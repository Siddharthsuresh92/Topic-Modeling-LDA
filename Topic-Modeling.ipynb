{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/siddharth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2019)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>more women urged to become councillors</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>most highly educated live in nsw wa</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>mp raises hospital concerns in parliament</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>mp rejects ambulance levy claims</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>mugabe to touch down in paris for summit</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>national gallery gets all clear after</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>nato gives green light to defend turkey</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>nca defends aboriginal tent embassy raid</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>new zealand imposes visa entry for zimbabwe</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>no side effects for new whooping cough vaccine</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>nsw govt under fire for holding back vegetation</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>nsw opp defends claims of running race campaign</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>nsw opp pledges 50m drought relief</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>nt govt boosts nurse number with overseas intake</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>nth koreans seek asylum at japanese embassy</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>nursing student intake down</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>oh brother your times up says ganguly senior</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>omodei to stay in politics</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>onesteel to invest 80m in whyalla steelworks</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>opposition urged to help protect recherche bay</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        headline_text  index\n",
       "100            more women urged to become councillors    100\n",
       "101               most highly educated live in nsw wa    101\n",
       "102         mp raises hospital concerns in parliament    102\n",
       "103                  mp rejects ambulance levy claims    103\n",
       "104          mugabe to touch down in paris for summit    104\n",
       "105             national gallery gets all clear after    105\n",
       "106           nato gives green light to defend turkey    106\n",
       "107          nca defends aboriginal tent embassy raid    107\n",
       "108       new zealand imposes visa entry for zimbabwe    108\n",
       "109    no side effects for new whooping cough vaccine    109\n",
       "110   nsw govt under fire for holding back vegetation    110\n",
       "111   nsw opp defends claims of running race campaign    111\n",
       "112                nsw opp pledges 50m drought relief    112\n",
       "113  nt govt boosts nurse number with overseas intake    113\n",
       "114       nth koreans seek asylum at japanese embassy    114\n",
       "115                       nursing student intake down    115\n",
       "116      oh brother your times up says ganguly senior    116\n",
       "117                        omodei to stay in politics    117\n",
       "118      onesteel to invest 80m in whyalla steelworks    118\n",
       "119    opposition urged to help protect recherche bay    119"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"abcnews-date-text.csv\")\n",
    "news = news.drop(columns = \"publish_date\")\n",
    "news['index'] = news.index\n",
    "news[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_news = news['headline_text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100                        [women, urge, councillors]\n",
       "101                           [highly, educate, live]\n",
       "102            [raise, hospital, concern, parliament]\n",
       "103                  [reject, ambulance, levy, claim]\n",
       "104                    [mugabe, touch, paris, summit]\n",
       "105                   [national, gallery, get, clear]\n",
       "106        [nato, give, green, light, defend, turkey]\n",
       "107         [defend, aboriginal, tent, embassy, raid]\n",
       "108          [zealand, impose, visa, entry, zimbabwe]\n",
       "109                   [effect, whoop, cough, vaccine]\n",
       "110                          [govt, hold, vegetation]\n",
       "111              [defend, claim, run, race, campaign]\n",
       "112                         [pledge, drought, relief]\n",
       "113    [govt, boost, nurse, number, overseas, intake]\n",
       "114        [koreans, seek, asylum, japanese, embassy]\n",
       "115                          [nurse, student, intake]\n",
       "116             [brother, time, say, ganguly, senior]\n",
       "117                          [omodei, stay, politics]\n",
       "118           [onesteel, invest, whyalla, steelworks]\n",
       "119      [opposition, urge, help, protect, recherche]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_news[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100                       [women, urg, councillor]\n",
       "101                             [high, educ, live]\n",
       "102            [rais, hospit, concern, parliament]\n",
       "103                   [reject, ambul, levi, claim]\n",
       "104                   [mugab, touch, pari, summit]\n",
       "105                  [nation, galleri, get, clear]\n",
       "106     [nato, give, green, light, defend, turkey]\n",
       "107        [defend, aborigin, tent, embassi, raid]\n",
       "108         [zealand, impos, visa, entri, zimbabw]\n",
       "109                 [effect, whoop, cough, vaccin]\n",
       "110                            [govt, hold, veget]\n",
       "111           [defend, claim, run, race, campaign]\n",
       "112                       [pledg, drought, relief]\n",
       "113    [govt, boost, nurs, number, oversea, intak]\n",
       "114       [korean, seek, asylum, japanes, embassi]\n",
       "115                         [nurs, student, intak]\n",
       "116          [brother, time, say, ganguli, senior]\n",
       "117                          [omodei, stay, polit]\n",
       "118         [onesteel, invest, whyalla, steelwork]\n",
       "119        [opposit, urg, help, protect, recherch]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_news[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemma</th>\n",
       "      <th>apt output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "      <td>caress</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "      <td>fly</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "      <td>deny</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "      <td>agree</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "      <td>own</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "      <td>humble</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "      <td>size</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "      <td>state</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "      <td>plot</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed        lemma apt output\n",
       "0       caresses  caress       caress     caress\n",
       "1          flies     fli          fly        fli\n",
       "2           dies     die          die        die\n",
       "3          mules    mule        mules       mule\n",
       "4         denied    deni         deny       deni\n",
       "5           died     die          die        die\n",
       "6         agreed    agre        agree       agre\n",
       "7          owned     own          own        own\n",
       "8        humbled   humbl       humble      humbl\n",
       "9          sized    size         size       size\n",
       "10       meeting    meet         meet       meet\n",
       "11       stating   state        state      state\n",
       "12       siezing    siez      siezing       siez\n",
       "13   itemization    item  itemization       item\n",
       "14   sensational  sensat  sensational     sensat\n",
       "15   traditional  tradit  traditional     tradit\n",
       "16     reference   refer    reference      refer\n",
       "17     colonizer   colon    colonizer      colon\n",
       "18       plotted    plot         plot       plot"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "stems = [stemmer.stem(plural) for plural in original_words]\n",
    "lemmas = [WordNetLemmatizer().lemmatize(plural, pos='v') for plural in original_words]\n",
    "lemma_stem = [stemmer.stem(WordNetLemmatizer().lemmatize(plural, pos='v')) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': stems, 'lemma': lemmas, 'apt output': lemma_stem})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
